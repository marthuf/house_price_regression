---
title: "House price prediction"
output: html_document
---

```{r, message=F, comment=NA}
require(dplyr)
require(ggplot2)
require(tidyr)
require(scales)
require(caret)

train <- read.csv('../data/train.csv')
test <- read.csv('../data/test.csv')

cat('dimensions: ', dim(train))
head(train)
```

note: this looks different for the training-set
```{r}
fraction_available <- sapply(test, function(col) 1 - mean(is.na(col)))
available_values <- data.frame(fraction_available)
available_values['variable'] <- row.names(available_values)
row.names(available_values) <- NULL
available_values['complete'] <- as.factor(available_values$fraction_available == 1)

ggplot(available_values, aes(x=variable, y=fraction_available, fill=complete) ) + 
  geom_bar( stat='identity' ) + 
  coord_flip() + 
  scale_fill_manual(values=c('gray50', 'gray80')) +
  ylab('fraction of values available') +
  ggtitle('Fraction of available (not NA) values') + 
  theme(plot.title=element_text(size=16, hjust=0.5))
```


## pre-process

We have to make sure that a feature is complete in both, training- and test-set. Otherwise it's of no use. Therefore, the fraction of available values (not NA values) is calculated for both. And used as information for the function 'impute_na' from 'pre_process.R'

```{r}
source('pre_process.R')

na_statsistics <- get_na_stats(train_df=train, test_df=test)
head(na_statsistics)
```

If the fraction of NA-values exceeds 10% in either training- or test-set, the feature is dropped for now. If a fraction of less than 10% is NA, the NA-values are imputed. For factors, a new factor level 'NA' is made. This just means that 'unknown' becomes it's own dummy variable. For numerical values, the NA-values are replaced with the median of the feature.


**Feature engineering:**
All features are either factor or numeric (has been checked). Some features with datatype 'numeric' are ordinal and it makes more sense to encode them as factor. If a feature has datatype numeric but only a few distinct values, that's a sign that it should maybe be used as a factor.


The test-set has no target-variable. It can be used for evaluation on kaggle but here in R we cannot evaluate the predictions on this test-set.

Therefore, we split the training-set in a 'real' training-set to build the models and a validation-set to test the models. Finally, the best model will be evaluated on the test-set.

**Note**:
Fixed bug: previously, the model was trained on the whole labelled dataset (train.csv) and evaluated on the validation set which is a part of this dataset. That's why the problem with rare factor levels did not occur (see function 'remove_rare_factor_levles' in 'pre_process.R').


## Modelling

just remove all columns with NAs in either training or test-set and build a model using all features.
```{r, echo=F, eval=F}
no_na <- read.csv('../data/train.csv') %>%
  feature_engineer() %>%
  remove_na_columns(na_stats=na_statsistics) %>%  # remove all columns containg NAs
  remove_rare_factor_levels()

split_data_no_na <- split_training_validation_ds(no_na, validation_fraction=0.2)
train_no_na <- split_data_no_na[[1]]
val_no_na <- split_data_no_na[[2]]

extremely_naive_model <- lm(data=train_no_na, SalePrice ~ .)
val_no_na['prediction'] <- predict(extremely_naive_model, newdata=val_no_na)
val_no_na['residual'] <- abs(val_no_na$SalePrice - val_no_na$prediction)

mad <- mean(val_no_na$residual)  # mean absolute eviation
cat(sprintf('MAD: %s\nmean sale-price: %s', round(mean(val_no_na$residual)), round(mean(val_no_na$SalePrice))))
```
...warning maybe because of multicolinearity


```{r}
train_processed <- pre_process_data(train)  # here columns with only a few NAs are imputed (not thrown away)

split_data <- split_training_validation_ds(train_processed, validation_fraction=0.2)
train <- split_data[[1]]
val <- split_data[[2]]
```

use somewhat pre-processed data (features with more than 10% NA removed, featrues with very few NAs imputed, some feature engineering). Then build a model using all features.
```{r}
naive_model <- lm(data=train, SalePrice ~ . )

val['prediction'] <- predict(naive_model, newdata=val)
val['residual'] <- abs(val$SalePrice - val$prediction)
val %>% select(SalePrice, prediction) %>% head()
```

```{r}
mad <- mean(val$residual)  # mean absolute eviation
cat(sprintf('MAD: %s\nmean sale-price: %s', round(mean(val$residual)), round(mean(val$SalePrice))))
```

```{r}
ggplot(val, aes(x=SalePrice, y=prediction) ) +
  geom_point() +
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma) +
  ylab('Vorhersage [$]') +
  xlab('Verkaufspreis [$]') +
  ggtitle('Modell-Vorhersage und Verkaufspreis') + 
  theme(plot.title=element_text(size=16, hjust=0.5))
ggsave('../talk/figures/simple_model.pdf')
```

============================================================================================================================================


## Identifizieren der Variablen mit den größten Effekten mit Hilfe von standardisierten Koeffizienten 

## Nachteil unstandardisierter Regressionskoeffizienten: 
Der Regressionskoeffizient gibt an, um wie viele Einheiten sich Y im Durchschnitt ?ndert, wenn X sich um eine absolute Einheit ?ndert. Deshalb ist der Regressionskoeffizient selbst von den Ma?einheiten von X und Y abh?ngig und daher schlechter vergleichbar.

## Ausweg: Standardisierte Koeffizienten (sog. "Beta-Koeffizienten")  

$\hat{\beta_i} = \beta_i*\frac{s_{x_i}}{s_y}$

$\beta_i$ = unstandardisierter Regressionkoeffizient

$s_{x_i}$ = Standardabweichung der unabh?ngigen Varibalbe $X_i$

$s_y$ = Standardabweichung der abh?ngigen Variable Y

Vorteil: $\hat{\beta_i}$ liegt idealerweise im Intervall [-1,1] (sonst Hinweis auf Mulitkollinearität) und kann daher sowohl der Richtung als auch der Stärke nach eindeutig interpretiert werden. 

Nachteil: Eignet sich nur für Variablen, bei denen die Standardabweichung sinnvoll interpretiert werden kann und nicht für den Vergleich verschiedener Stichproben


```{r}
stand_model <- lm(data=train_processed, scale(SalePrice) ~ 0 + scale(LotArea) + scale(YearRemodAdd) + scale(MasVnrArea) + scale(X1stFlrSF) + scale(X2ndFlrSF) + scale(GarageArea) + scale(WoodDeckSF) + scale(ScreenPorch) + scale(OverallQual))

summary(stand_model)
```

